{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1.1 Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:07:56.294945Z","iopub.execute_input":"2026-01-31T11:07:56.295114Z","iopub.status.idle":"2026-01-31T11:08:07.838092Z","shell.execute_reply.started":"2026-01-31T11:07:56.295094Z","shell.execute_reply":"2026-01-31T11:08:07.837505Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 1.2 Define Paths","metadata":{}},{"cell_type":"code","source":"MRI_DATASET_PATH = \"/kaggle/input/imagesoasis/Data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:33:15.954471Z","iopub.execute_input":"2026-01-31T11:33:15.955152Z","iopub.status.idle":"2026-01-31T11:33:15.958457Z","shell.execute_reply.started":"2026-01-31T11:33:15.955120Z","shell.execute_reply":"2026-01-31T11:33:15.957681Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# 1.3 Data Transforms","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:33:21.137228Z","iopub.execute_input":"2026-01-31T11:33:21.137962Z","iopub.status.idle":"2026-01-31T11:33:21.141705Z","shell.execute_reply.started":"2026-01-31T11:33:21.137931Z","shell.execute_reply":"2026-01-31T11:33:21.140968Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# 1.4 Load Data","metadata":{}},{"cell_type":"code","source":"dataset = ImageFolder(MRI_DATASET_PATH, transform=transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:33:24.329668Z","iopub.execute_input":"2026-01-31T11:33:24.329934Z","iopub.status.idle":"2026-01-31T11:34:57.355512Z","shell.execute_reply.started":"2026-01-31T11:33:24.329913Z","shell.execute_reply":"2026-01-31T11:34:57.354852Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# 1.5 Load ResNet-50","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel_mri = models.resnet50(pretrained=True)\nmodel_mri.fc = nn.Linear(model_mri.fc.in_features, 4)\nmodel_mri = model_mri.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:01.606204Z","iopub.execute_input":"2026-01-31T11:35:01.606931Z","iopub.status.idle":"2026-01-31T11:35:02.046174Z","shell.execute_reply.started":"2026-01-31T11:35:01.606903Z","shell.execute_reply":"2026-01-31T11:35:02.045626Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Total images:\", len(dataset))\nprint(\"Train size:\", len(train_ds))\nprint(\"Batches:\", len(train_loader))\nprint(\"Classes:\", dataset.classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:06.428342Z","iopub.execute_input":"2026-01-31T11:35:06.429020Z","iopub.status.idle":"2026-01-31T11:35:06.433406Z","shell.execute_reply.started":"2026-01-31T11:35:06.428993Z","shell.execute_reply":"2026-01-31T11:35:06.432738Z"}},"outputs":[{"name":"stdout","text":"Total images: 86437\nTrain size: 69149\nBatches: 2161\nClasses: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\n\ndataset = ImageFolder(MRI_DATASET_PATH)\n\nprint(\"Classes found:\", dataset.classes)\nprint(\"Total images:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:09.591482Z","iopub.execute_input":"2026-01-31T11:35:09.592030Z","iopub.status.idle":"2026-01-31T11:35:49.262570Z","shell.execute_reply.started":"2026-01-31T11:35:09.592004Z","shell.execute_reply":"2026-01-31T11:35:49.261885Z"}},"outputs":[{"name":"stdout","text":"Classes found: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\nTotal images: 86437\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.Resize((160,160)),   # faster\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\ndataset = ImageFolder(MRI_DATASET_PATH, transform=transform)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=32, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:55.823547Z","iopub.execute_input":"2026-01-31T11:35:55.824035Z","iopub.status.idle":"2026-01-31T11:36:16.577762Z","shell.execute_reply.started":"2026-01-31T11:35:55.824010Z","shell.execute_reply":"2026-01-31T11:36:16.577133Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# 1.6 Train MRI Model","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_mri.parameters(), lr=1e-4)\n\nfor epoch in range(5):\n    model_mri.train()\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        outputs = model_mri(x)\n        loss = criterion(outputs, y)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:36:22.472441Z","iopub.execute_input":"2026-01-31T11:36:22.473292Z","iopub.status.idle":"2026-01-31T11:55:35.985195Z","shell.execute_reply.started":"2026-01-31T11:36:22.473263Z","shell.execute_reply":"2026-01-31T11:55:35.984383Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0945\nEpoch [2/5], Loss: 0.0199\nEpoch [3/5], Loss: 0.0130\nEpoch [4/5], Loss: 0.0109\nEpoch [5/5], Loss: 0.0083\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def accuracy(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == y).sum().item()\n            total += y.size(0)\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:58:49.996560Z","iopub.execute_input":"2026-01-31T11:58:49.997162Z","iopub.status.idle":"2026-01-31T11:58:50.001516Z","shell.execute_reply.started":"2026-01-31T11:58:49.997135Z","shell.execute_reply":"2026-01-31T11:58:50.000824Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"for epoch in range(5):\n    model_mri.train()\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model_mri(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    # Compute validation accuracy\n    val_acc = accuracy(model_mri, val_loader)\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_acc*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:59:07.786578Z","iopub.execute_input":"2026-01-31T11:59:07.786874Z","iopub.status.idle":"2026-01-31T12:21:03.373640Z","shell.execute_reply.started":"2026-01-31T11:59:07.786850Z","shell.execute_reply":"2026-01-31T12:21:03.372727Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0073, Val Accuracy: 99.97%\nEpoch [2/5], Loss: 0.0054, Val Accuracy: 99.85%\nEpoch [3/5], Loss: 0.0059, Val Accuracy: 99.92%\nEpoch [4/5], Loss: 0.0042, Val Accuracy: 99.98%\nEpoch [5/5], Loss: 0.0016, Val Accuracy: 100.00%\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"transforms.RandomRotation(15),\ntransforms.RandomHorizontalFlip(),\ntransforms.RandomResizedCrop(224, scale=(0.8,1.0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:21:21.227038Z","iopub.execute_input":"2026-01-31T12:21:21.227314Z","iopub.status.idle":"2026-01-31T12:21:21.234229Z","shell.execute_reply.started":"2026-01-31T12:21:21.227287Z","shell.execute_reply":"2026-01-31T12:21:21.233487Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Patient-Level Prediction Example","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef patient_level_predict(model, patient_slices):\n    model.eval()\n    outputs = []\n    with torch.no_grad():\n        for x in patient_slices:\n            x = x.to(device).unsqueeze(0)\n            out = model(x)\n            outputs.append(out.cpu().numpy())\n    avg_output = np.mean(outputs, axis=0)\n    return np.argmax(avg_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:21:30.091476Z","iopub.execute_input":"2026-01-31T12:21:30.092256Z","iopub.status.idle":"2026-01-31T12:21:30.096487Z","shell.execute_reply.started":"2026-01-31T12:21:30.092228Z","shell.execute_reply":"2026-01-31T12:21:30.095912Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# 1.7 Save MRI Model","metadata":{}},{"cell_type":"code","source":"torch.save(model_mri.state_dict(), \"mri_resnet50.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:56:51.734288Z","iopub.execute_input":"2026-01-31T11:56:51.734655Z","iopub.status.idle":"2026-01-31T11:56:51.867401Z","shell.execute_reply.started":"2026-01-31T11:56:51.734603Z","shell.execute_reply":"2026-01-31T11:56:51.866825Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## HANDWRITING MODEL","metadata":{}},{"cell_type":"markdown","source":"# 2.1 Load Dataset","metadata":{}},{"cell_type":"code","source":"HW_PATH = \"/kaggle/input/handwriting-data-to-detect-alzheimers-disease\"\n\nhw_dataset = ImageFolder(HW_PATH, transform=transform)\ntrain_hw, val_hw = torch.utils.data.random_split(hw_dataset, [80, 20])\n\ntrain_hw_loader = DataLoader(train_hw, batch_size=16, shuffle=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.2 Load ResNet-18","metadata":{}},{"cell_type":"code","source":"model_hw = models.resnet18(pretrained=True)\nmodel_hw.fc = nn.Linear(model_hw.fc.in_features, 2)\nmodel_hw = model_hw.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.3 Train Handwriting Model","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model_hw.parameters(), lr=1e-4)\n\nfor epoch in range(10):\n    for x, y in train_hw_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model_hw(x), y)\n        loss.backward()\n        optimizer.step()\n    print(f\"HW Epoch {epoch+1} done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.4 Save Model","metadata":{}},{"cell_type":"code","source":"torch.save(model_hw.state_dict(), \"handwriting_model.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FEATURE EXTRACTION","metadata":{}},{"cell_type":"markdown","source":"# 3.1 Remove Final Layers","metadata":{}},{"cell_type":"code","source":"mri_feature_extractor = nn.Sequential(*list(model_mri.children())[:-1])\nhw_feature_extractor = nn.Sequential(*list(model_hw.children())[:-1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3.2 Extract Features","metadata":{}},{"cell_type":"code","source":"def extract_features(model, loader):\n    features = []\n    labels = []\n    model.eval()\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            f = model(x).squeeze()\n            features.append(f.cpu())\n            labels.append(y)\n    return torch.cat(features), torch.cat(labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FUSION NETWORK","metadata":{}},{"cell_type":"markdown","source":"# 4.1 Fusion Model","metadata":{}},{"cell_type":"code","source":"class FusionNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(512+512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 4)\n        )\n\n    def forward(self, mri, hw):\n        x = torch.cat([mri, hw], dim=1)\n        return self.fc(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}