{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493},{"sourceId":6278618,"sourceType":"datasetVersion","datasetId":3609813}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1.1 Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:07:56.294945Z","iopub.execute_input":"2026-01-31T11:07:56.295114Z","iopub.status.idle":"2026-01-31T11:08:07.838092Z","shell.execute_reply.started":"2026-01-31T11:07:56.295094Z","shell.execute_reply":"2026-01-31T11:08:07.837505Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 1.2 Define Paths","metadata":{}},{"cell_type":"code","source":"MRI_DATASET_PATH = \"/kaggle/input/imagesoasis/Data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:33:15.954471Z","iopub.execute_input":"2026-01-31T11:33:15.955152Z","iopub.status.idle":"2026-01-31T11:33:15.958457Z","shell.execute_reply.started":"2026-01-31T11:33:15.955120Z","shell.execute_reply":"2026-01-31T11:33:15.957681Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# 1.3 Data Transforms","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:33:21.137228Z","iopub.execute_input":"2026-01-31T11:33:21.137962Z","iopub.status.idle":"2026-01-31T11:33:21.141705Z","shell.execute_reply.started":"2026-01-31T11:33:21.137931Z","shell.execute_reply":"2026-01-31T11:33:21.140968Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# 1.4 Load Data","metadata":{}},{"cell_type":"code","source":"dataset = ImageFolder(MRI_DATASET_PATH, transform=transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:33:24.329668Z","iopub.execute_input":"2026-01-31T11:33:24.329934Z","iopub.status.idle":"2026-01-31T11:34:57.355512Z","shell.execute_reply.started":"2026-01-31T11:33:24.329913Z","shell.execute_reply":"2026-01-31T11:34:57.354852Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# 1.5 Load ResNet-50","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel_mri = models.resnet50(pretrained=True)\nmodel_mri.fc = nn.Linear(model_mri.fc.in_features, 4)\nmodel_mri = model_mri.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:01.606204Z","iopub.execute_input":"2026-01-31T11:35:01.606931Z","iopub.status.idle":"2026-01-31T11:35:02.046174Z","shell.execute_reply.started":"2026-01-31T11:35:01.606903Z","shell.execute_reply":"2026-01-31T11:35:02.045626Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Total images:\", len(dataset))\nprint(\"Train size:\", len(train_ds))\nprint(\"Batches:\", len(train_loader))\nprint(\"Classes:\", dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:06.428342Z","iopub.execute_input":"2026-01-31T11:35:06.429020Z","iopub.status.idle":"2026-01-31T11:35:06.433406Z","shell.execute_reply.started":"2026-01-31T11:35:06.428993Z","shell.execute_reply":"2026-01-31T11:35:06.432738Z"}},"outputs":[{"name":"stdout","text":"Total images: 86437\nTrain size: 69149\nBatches: 2161\nClasses: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.Resize((160,160)),   # faster\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\ndataset = ImageFolder(MRI_DATASET_PATH, transform=transform)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=32, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:35:55.823547Z","iopub.execute_input":"2026-01-31T11:35:55.824035Z","iopub.status.idle":"2026-01-31T11:36:16.577762Z","shell.execute_reply.started":"2026-01-31T11:35:55.824010Z","shell.execute_reply":"2026-01-31T11:36:16.577133Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# 1.6 Train MRI Model","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_mri.parameters(), lr=1e-4)\n\nfor epoch in range(5):\n    model_mri.train()\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        outputs = model_mri(x)\n        loss = criterion(outputs, y)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:36:22.472441Z","iopub.execute_input":"2026-01-31T11:36:22.473292Z","iopub.status.idle":"2026-01-31T11:55:35.985195Z","shell.execute_reply.started":"2026-01-31T11:36:22.473263Z","shell.execute_reply":"2026-01-31T11:55:35.984383Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0945\nEpoch [2/5], Loss: 0.0199\nEpoch [3/5], Loss: 0.0130\nEpoch [4/5], Loss: 0.0109\nEpoch [5/5], Loss: 0.0083\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Accuracy","metadata":{}},{"cell_type":"code","source":"def accuracy(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == y).sum().item()\n            total += y.size(0)\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:58:49.996560Z","iopub.execute_input":"2026-01-31T11:58:49.997162Z","iopub.status.idle":"2026-01-31T11:58:50.001516Z","shell.execute_reply.started":"2026-01-31T11:58:49.997135Z","shell.execute_reply":"2026-01-31T11:58:50.000824Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Testing Epochs","metadata":{}},{"cell_type":"code","source":"for epoch in range(5):\n    model_mri.train()\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model_mri(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    # Compute validation accuracy\n    val_acc = accuracy(model_mri, val_loader)\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_acc*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T11:59:07.786578Z","iopub.execute_input":"2026-01-31T11:59:07.786874Z","iopub.status.idle":"2026-01-31T12:21:03.373640Z","shell.execute_reply.started":"2026-01-31T11:59:07.786850Z","shell.execute_reply":"2026-01-31T12:21:03.372727Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0073, Val Accuracy: 99.97%\nEpoch [2/5], Loss: 0.0054, Val Accuracy: 99.85%\nEpoch [3/5], Loss: 0.0059, Val Accuracy: 99.92%\nEpoch [4/5], Loss: 0.0042, Val Accuracy: 99.98%\nEpoch [5/5], Loss: 0.0016, Val Accuracy: 100.00%\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"transforms.RandomRotation(15),\ntransforms.RandomHorizontalFlip(),\ntransforms.RandomResizedCrop(224, scale=(0.8,1.0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:21:21.227038Z","iopub.execute_input":"2026-01-31T12:21:21.227314Z","iopub.status.idle":"2026-01-31T12:21:21.234229Z","shell.execute_reply.started":"2026-01-31T12:21:21.227287Z","shell.execute_reply":"2026-01-31T12:21:21.233487Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Patient-Level Prediction Example","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef patient_level_predict(model, patient_slices):\n    model.eval()\n    outputs = []\n    with torch.no_grad():\n        for x in patient_slices:\n            x = x.to(device).unsqueeze(0)\n            out = model(x)\n            outputs.append(out.cpu().numpy())\n    avg_output = np.mean(outputs, axis=0)\n    return np.argmax(avg_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:21:47.750105Z","iopub.execute_input":"2026-01-31T12:21:47.750713Z","iopub.status.idle":"2026-01-31T12:21:47.754996Z","shell.execute_reply.started":"2026-01-31T12:21:47.750688Z","shell.execute_reply":"2026-01-31T12:21:47.754358Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# 1.7 Save MRI Model","metadata":{}},{"cell_type":"code","source":"torch.save(model_mri.state_dict(), \"mri_resnet50.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:21:51.614327Z","iopub.execute_input":"2026-01-31T12:21:51.614924Z","iopub.status.idle":"2026-01-31T12:21:51.845108Z","shell.execute_reply.started":"2026-01-31T12:21:51.614895Z","shell.execute_reply":"2026-01-31T12:21:51.844517Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## HANDWRITING MODEL","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:38:10.052848Z","iopub.execute_input":"2026-01-31T12:38:10.053433Z","iopub.status.idle":"2026-01-31T12:38:10.056867Z","shell.execute_reply.started":"2026-01-31T12:38:10.053405Z","shell.execute_reply":"2026-01-31T12:38:10.056189Z"}},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"# 2.1 Load Dataset","metadata":{}},{"cell_type":"code","source":"# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:40:45.557429Z","iopub.execute_input":"2026-01-31T12:40:45.558078Z","iopub.status.idle":"2026-01-31T12:40:45.583459Z","shell.execute_reply.started":"2026-01-31T12:40:45.558040Z","shell.execute_reply":"2026-01-31T12:40:45.582834Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n# Check first rows\nprint(df.head())\n\n# Since no label exists, create dummy labels for testing\n# 0 = Healthy, 1 = Alzheimer\n# For real use, replace this with actual labels if available\nnp.random.seed(42)\ndf['label'] = np.random.randint(0, 2, size=len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:42:25.188959Z","iopub.execute_input":"2026-01-31T12:42:25.189678Z","iopub.status.idle":"2026-01-31T12:42:25.236603Z","shell.execute_reply.started":"2026-01-31T12:42:25.189651Z","shell.execute_reply":"2026-01-31T12:42:25.235929Z"}},"outputs":[{"name":"stdout","text":"     ID  air_time1  disp_index1  gmrt_in_air1  gmrt_on_paper1  \\\n0  id_1       5160     0.000013    120.804174       86.853334   \n1  id_2      51980     0.000016    115.318238       83.448681   \n2  id_3       2600     0.000010    229.933997      172.761858   \n3  id_4       2130     0.000010    369.403342      183.193104   \n4  id_5       2310     0.000007    257.997131      111.275889   \n\n   max_x_extension1  max_y_extension1  mean_acc_in_air1  mean_acc_on_paper1  \\\n0               957              6601          0.361800            0.217459   \n1              1694              6998          0.272513            0.144880   \n2              2333              5802          0.387020            0.181342   \n3              1756              8159          0.556879            0.164502   \n4               987              4732          0.266077            0.145104   \n\n   mean_gmrt1  ...  mean_jerk_in_air25  mean_jerk_on_paper25  \\\n0  103.828754  ...            0.141434              0.024471   \n1   99.383459  ...            0.049663              0.018368   \n2  201.347928  ...            0.178194              0.017174   \n3  276.298223  ...            0.113905              0.019860   \n4  184.636510  ...            0.121782              0.020872   \n\n   mean_speed_in_air25  mean_speed_on_paper25  num_of_pendown25  paper_time25  \\\n0             5.596487               3.184589                71         40120   \n1             1.665973               0.950249               129        126700   \n2             4.000781               2.392521                74         45480   \n3             4.206746               1.613522               123         67945   \n4             3.319036               1.680629                92         37285   \n\n   pressure_mean25  pressure_var25  total_time25  class  \n0      1749.278166     296102.7676        144605      P  \n1      1504.768272     278744.2850        298640      P  \n2      1431.443492     144411.7055         79025      P  \n3      1465.843329     230184.7154        181220      P  \n4      1841.702561     158290.0255         72575      P  \n\n[5 rows x 452 columns]\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"# Features: all numeric columns except ID\nX = df.drop(columns=['ID','label'])\n\n# Convert to numeric in case any column is object\nX = X.apply(pd.to_numeric, errors='coerce')\n\n# Fill missing values if any\nX = X.fillna(0).values\n\n# Labels\ny = df['label'].values.astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:42:37.885258Z","iopub.execute_input":"2026-01-31T12:42:37.885880Z","iopub.status.idle":"2026-01-31T12:42:37.930302Z","shell.execute_reply.started":"2026-01-31T12:42:37.885855Z","shell.execute_reply":"2026-01-31T12:42:37.929506Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"# 2.2 Pytorch Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass HandwritingFeaturesDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n    def __len__(self):\n        return len(self.y)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ndataset = HandwritingFeaturesDataset(X, y)\n\n# Train/Validation split\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:42:48.791847Z","iopub.execute_input":"2026-01-31T12:42:48.792146Z","iopub.status.idle":"2026-01-31T12:42:48.808299Z","shell.execute_reply.started":"2026-01-31T12:42:48.792122Z","shell.execute_reply":"2026-01-31T12:42:48.807532Z"}},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":"# 2.3 Define MLP Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass HandwritingMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 2)  # 2 classes: Healthy / Alzheimer\n        )\n    def forward(self, x):\n        return self.fc(x)\n\nmodel_hw = HandwritingMLP(X.shape[1])\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_hw = model_hw.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_hw.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:43:13.421409Z","iopub.execute_input":"2026-01-31T12:43:13.421992Z","iopub.status.idle":"2026-01-31T12:43:13.430176Z","shell.execute_reply.started":"2026-01-31T12:43:13.421965Z","shell.execute_reply":"2026-01-31T12:43:13.429484Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    model_hw.train()\n    total_loss = 0\n    total_correct = 0\n    \n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model_hw(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        preds = torch.argmax(outputs, dim=1)\n        total_correct += torch.sum(preds == y).item()\n    \n    acc = total_correct / len(train_ds)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:43:38.288004Z","iopub.execute_input":"2026-01-31T12:43:38.288288Z","iopub.status.idle":"2026-01-31T12:43:38.484509Z","shell.execute_reply.started":"2026-01-31T12:43:38.288264Z","shell.execute_reply":"2026-01-31T12:43:38.483738Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 5369.4382, Accuracy: 0.5396\nEpoch 2/10, Loss: 3715.6108, Accuracy: 0.5036\nEpoch 3/10, Loss: 1693.4537, Accuracy: 0.5971\nEpoch 4/10, Loss: 675.0823, Accuracy: 0.6331\nEpoch 5/10, Loss: 882.9556, Accuracy: 0.6619\nEpoch 6/10, Loss: 290.1693, Accuracy: 0.7122\nEpoch 7/10, Loss: 242.5250, Accuracy: 0.7194\nEpoch 8/10, Loss: 202.0962, Accuracy: 0.7770\nEpoch 9/10, Loss: 214.7288, Accuracy: 0.7626\nEpoch 10/10, Loss: 182.4026, Accuracy: 0.7986\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"# 2.4 Save Model","metadata":{}},{"cell_type":"code","source":"torch.save(model_hw.state_dict(), \"handwriting_mlp_model.pth\")\nprint(\"Handwriting MLP model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:44:59.892792Z","iopub.execute_input":"2026-01-31T12:44:59.893065Z","iopub.status.idle":"2026-01-31T12:44:59.899581Z","shell.execute_reply.started":"2026-01-31T12:44:59.893036Z","shell.execute_reply":"2026-01-31T12:44:59.898850Z"}},"outputs":[{"name":"stdout","text":"Handwriting MLP model saved successfully!\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nimport torch.nn as nn\n\n# Load pretrained ResNet50\nresnet50 = models.resnet50(pretrained=True)\n\n# Replace final layer to match your classes (4 Alzheimer stages)\nnum_classes = 4\nresnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nresnet50 = resnet50.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:47:32.599544Z","iopub.execute_input":"2026-01-31T12:47:32.600234Z","iopub.status.idle":"2026-01-31T12:47:33.032949Z","shell.execute_reply.started":"2026-01-31T12:47:32.600205Z","shell.execute_reply":"2026-01-31T12:47:33.032163Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import datasets, transforms, models\nimport torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:50:16.615806Z","iopub.execute_input":"2026-01-31T12:50:16.616534Z","iopub.status.idle":"2026-01-31T12:50:16.620074Z","shell.execute_reply.started":"2026-01-31T12:50:16.616504Z","shell.execute_reply":"2026-01-31T12:50:16.619457Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nMRI_PATH = \"/kaggle/input/imagesoasis/Data\" # replace with actual path\n\nmri_dataset = datasets.ImageFolder(MRI_PATH, transform=transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:50:49.788221Z","iopub.execute_input":"2026-01-31T12:50:49.788542Z","iopub.status.idle":"2026-01-31T12:52:24.314096Z","shell.execute_reply.started":"2026-01-31T12:50:49.788518Z","shell.execute_reply":"2026-01-31T12:52:24.313505Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# Image transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # ResNet requires 224x224\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean\n                         [0.229, 0.224, 0.225])  # ImageNet std\n])\n\n# Path to your MRI images in Kaggle input\nMRI_PATH = \"/kaggle/input/imagesoasis/Data\"  # replace with your path\n\n# Assuming folder structure: \n# /MRI_PATH/class_name/image.jpg\nmri_dataset = datasets.ImageFolder(MRI_PATH, transform=transform)\n\n# Split train/val\ntrain_size = int(0.8 * len(mri_dataset))\nval_size = len(mri_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(mri_dataset, [train_size, val_size])\n\n# DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T12:59:06.078060Z","iopub.execute_input":"2026-01-31T12:59:06.078610Z","iopub.status.idle":"2026-01-31T13:00:44.970961Z","shell.execute_reply.started":"2026-01-31T12:59:06.078583Z","shell.execute_reply":"2026-01-31T13:00:44.970323Z"}},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":"# Load pretrained ResNet-50","metadata":{}},{"cell_type":"code","source":"# Load pretrained ResNet-50\nresnet50 = models.resnet50(pretrained=True)\n\n# Change the final fully connected layer to match your number of classes\nnum_classes = len(mri_dataset.classes)  # automatically get number of classes from folder names\nresnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n\n# Move to GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nresnet50 = resnet50.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(resnet50.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T13:03:22.114362Z","iopub.execute_input":"2026-01-31T13:03:22.115130Z","iopub.status.idle":"2026-01-31T13:03:22.530474Z","shell.execute_reply.started":"2026-01-31T13:03:22.115102Z","shell.execute_reply":"2026-01-31T13:03:22.529901Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"# Train the ResNet-50 model","metadata":{}},{"cell_type":"code","source":"num_epochs = 5  # you can increase to 10-20 for better performance\n\nfor epoch in range(num_epochs):\n    resnet50.train()\n    total_loss = 0\n    total_correct = 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = resnet50(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        preds = torch.argmax(outputs, dim=1)\n        total_correct += torch.sum(preds == labels).item()\n    \n    train_acc = total_correct / len(train_loader.dataset)\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {avg_loss:.4f}, Accuracy: {train_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T13:03:36.558886Z","iopub.execute_input":"2026-01-31T13:03:36.559503Z","iopub.status.idle":"2026-01-31T13:59:38.315641Z","shell.execute_reply.started":"2026-01-31T13:03:36.559475Z","shell.execute_reply":"2026-01-31T13:59:38.314969Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5 — Loss: 0.1135, Accuracy: 0.9581\nEpoch 2/5 — Loss: 0.0251, Accuracy: 0.9919\nEpoch 3/5 — Loss: 0.0149, Accuracy: 0.9950\nEpoch 4/5 — Loss: 0.0119, Accuracy: 0.9958\nEpoch 5/5 — Loss: 0.0092, Accuracy: 0.9968\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"# Validate The Model ","metadata":{}},{"cell_type":"code","source":"resnet50.eval()\ntotal_correct = 0\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = resnet50(images)\n        preds = torch.argmax(outputs, dim=1)\n        total_correct += torch.sum(preds == labels).item()\n\nval_acc = total_correct / len(val_loader.dataset)\nprint(f\"Validation Accuracy: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T13:59:50.888725Z","iopub.execute_input":"2026-01-31T13:59:50.889027Z","iopub.status.idle":"2026-01-31T14:01:34.458516Z","shell.execute_reply.started":"2026-01-31T13:59:50.889000Z","shell.execute_reply":"2026-01-31T14:01:34.457861Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.9997\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"# Save The Trained Model","metadata":{}},{"cell_type":"code","source":"torch.save(resnet50.state_dict(), \"resnet50_mri.pth\")\nprint(\"ResNet-50 MRI model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:01:48.567156Z","iopub.execute_input":"2026-01-31T14:01:48.567744Z","iopub.status.idle":"2026-01-31T14:01:48.691409Z","shell.execute_reply.started":"2026-01-31T14:01:48.567715Z","shell.execute_reply":"2026-01-31T14:01:48.690821Z"}},"outputs":[{"name":"stdout","text":"ResNet-50 MRI model saved successfully!\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"# Step 3: Extract MRI Embeddings\n\nWe remove the final fully connected layer from the trained ResNet-50\nso we can use the feature vectors (embeddings) from each MRI.\nThese embeddings will later be concatenated with handwriting embeddings\nfor the fusion network.\n","metadata":{}},{"cell_type":"markdown","source":"## Extract MRI embeddings","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\n# Remove final classification layer\nresnet_features = nn.Sequential(*list(resnet50.children())[:-1])\nresnet_features = resnet_features.to(device)\nresnet_features.eval()\n\n# Function to extract embeddings\ndef extract_mri_embeddings(dataloader):\n    embeddings = []\n    labels = []\n    with torch.no_grad():\n        for images, lbls in dataloader:\n            images = images.to(device)\n            emb = resnet_features(images)  # shape [batch, 2048, 1, 1]\n            emb = emb.view(emb.size(0), -1)  # flatten to [batch, 2048]\n            embeddings.append(emb.cpu())\n            labels.append(lbls)\n    embeddings = torch.cat(embeddings, dim=0)\n    labels = torch.cat(labels, dim=0)\n    return embeddings, labels\n\ntrain_mri_emb, train_mri_lbl = extract_mri_embeddings(train_loader)\nval_mri_emb, val_mri_lbl = extract_mri_embeddings(val_loader)\n\nprint(\"MRI Embeddings shape:\", train_mri_emb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:02:26.619840Z","iopub.execute_input":"2026-01-31T14:02:26.620362Z","iopub.status.idle":"2026-01-31T14:10:52.010704Z","shell.execute_reply.started":"2026-01-31T14:02:26.620337Z","shell.execute_reply":"2026-01-31T14:10:52.009732Z"}},"outputs":[{"name":"stdout","text":"MRI Embeddings shape: torch.Size([69149, 2048])\n","output_type":"stream"}],"execution_count":96},{"cell_type":"markdown","source":"# Step 3b: Extract Handwriting Embeddings\n\nWe take the last hidden layer of the trained Handwriting MLP\nas the embedding for each patient. These will be fused\nwith the MRI embeddings for multimodal prediction.\n","metadata":{}},{"cell_type":"markdown","source":"# Extract handwriting embeddings","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport torch\n\n# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n# Drop 'ID' column\nX = df.drop(columns=[\"ID\"]).values\n\n# NOTE: You need labels for Alzheimer vs healthy\n# If you have a column like 'label', use it. Otherwise, create a dummy label (0/1) for demo\n# For now, let's create dummy labels (replace this with your real labels)\ny = torch.zeros(X.shape[0], dtype=torch.long)  # all zeros (healthy)\n# If you have a real column:\n# y = df['label'].values\n\n# Split train/val\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_val = scaler.transform(X_val)\n\n# Convert to torch tensors\nX_scaled_train = torch.tensor(X_scaled_train, dtype=torch.float32)\nX_scaled_val = torch.tensor(X_scaled_val, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\ny_val = torch.tensor(y_val, dtype=torch.long)\n\nprint(\"Handwriting train shape:\", X_scaled_train.shape)\nprint(\"Handwriting val shape:\", X_scaled_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:13:17.346613Z","iopub.execute_input":"2026-01-31T14:13:17.346988Z","iopub.status.idle":"2026-01-31T14:13:17.389508Z","shell.execute_reply.started":"2026-01-31T14:13:17.346960Z","shell.execute_reply":"2026-01-31T14:13:17.388505Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1198283475.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Standardize features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mX_scaled_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mX_scaled_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'H'"],"ename":"ValueError","evalue":"could not convert string to float: 'H'","output_type":"error"}],"execution_count":99},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport torch\n\n# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n# Drop ID column\ndf_numeric = df.drop(columns=[\"ID\"])\n\n# Check all columns are numeric\nprint(df_numeric.dtypes)\n\n# Convert to numeric just in case\ndf_numeric = df_numeric.apply(pd.to_numeric, errors='coerce')\n\n# Fill any missing values\ndf_numeric = df_numeric.fillna(0)\n\n# Features X\nX = df_numeric.values\n\n# Labels: for now, dummy labels (replace with real if available)\ny = torch.zeros(X.shape[0], dtype=torch.long)  # all zeros (healthy)\n# If you have a column 'label':\n# y = df['label'].values\n\n# Train/val split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize numeric features\nscaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_val = scaler.transform(X_val)\n\n# Convert to torch tensors\nX_scaled_train = torch.tensor(X_scaled_train, dtype=torch.float32)\nX_scaled_val = torch.tensor(X_scaled_val, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\ny_val = torch.tensor(y_val, dtype=torch.long)\n\nprint(\"Handwriting train shape:\", X_scaled_train.shape)\nprint(\"Handwriting val shape:\", X_scaled_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:14:07.706400Z","iopub.execute_input":"2026-01-31T14:14:07.706701Z","iopub.status.idle":"2026-01-31T14:14:07.771711Z","shell.execute_reply.started":"2026-01-31T14:14:07.706675Z","shell.execute_reply":"2026-01-31T14:14:07.770916Z"}},"outputs":[{"name":"stdout","text":"air_time1             int64\ndisp_index1         float64\ngmrt_in_air1        float64\ngmrt_on_paper1      float64\nmax_x_extension1      int64\n                     ...   \npaper_time25          int64\npressure_mean25     float64\npressure_var25      float64\ntotal_time25          int64\nclass                object\nLength: 451, dtype: object\nHandwriting train shape: torch.Size([139, 451])\nHandwriting val shape: torch.Size([35, 451])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1290033365.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train = torch.tensor(y_train, dtype=torch.long)\n/tmp/ipykernel_55/1290033365.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_val = torch.tensor(y_val, dtype=torch.long)\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"train_hw_emb = model_hw(X_scaled_train.to(device), return_embedding=True)\nval_hw_emb = model_hw(X_scaled_val.to(device), return_embedding=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:14:28.549697Z","iopub.execute_input":"2026-01-31T14:14:28.550271Z","iopub.status.idle":"2026-01-31T14:14:28.557158Z","shell.execute_reply.started":"2026-01-31T14:14:28.550240Z","shell.execute_reply":"2026-01-31T14:14:28.556243Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1416555462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_hw_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_hw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_hw_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_hw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: HandwritingMLP.forward() got an unexpected keyword argument 'return_embedding'"],"ename":"TypeError","evalue":"HandwritingMLP.forward() got an unexpected keyword argument 'return_embedding'","output_type":"error"}],"execution_count":102},{"cell_type":"code","source":"import torch.nn as nn\n\nclass HandwritingMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 64)  # this will be the embedding\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(64, 2)    # output layer (binary classification)\n\n    def forward(self, x, return_embedding=False):\n        x = self.relu1(self.fc1(x))\n        emb = self.relu2(self.fc2(x))  # embeddings\n        out = self.fc3(emb)\n        if return_embedding:\n            return emb\n        else:\n            return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:15:08.536064Z","iopub.execute_input":"2026-01-31T14:15:08.536337Z","iopub.status.idle":"2026-01-31T14:15:08.542061Z","shell.execute_reply.started":"2026-01-31T14:15:08.536312Z","shell.execute_reply":"2026-01-31T14:15:08.541518Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"input_dim = X_scaled_train.shape[1]  # number of features\nmodel_hw = HandwritingMLP(input_dim)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_hw = model_hw.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:15:21.760907Z","iopub.execute_input":"2026-01-31T14:15:21.761346Z","iopub.status.idle":"2026-01-31T14:15:21.767026Z","shell.execute_reply.started":"2026-01-31T14:15:21.761319Z","shell.execute_reply":"2026-01-31T14:15:21.766379Z"}},"outputs":[],"execution_count":104},{"cell_type":"code","source":"train_hw_emb = model_hw(X_scaled_train.to(device), return_embedding=True)\nval_hw_emb = model_hw(X_scaled_val.to(device), return_embedding=True)\n\nprint(\"Handwriting embeddings shape:\", train_hw_emb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:15:31.319142Z","iopub.execute_input":"2026-01-31T14:15:31.319399Z","iopub.status.idle":"2026-01-31T14:15:31.325389Z","shell.execute_reply.started":"2026-01-31T14:15:31.319378Z","shell.execute_reply":"2026-01-31T14:15:31.324492Z"}},"outputs":[{"name":"stdout","text":"Handwriting embeddings shape: torch.Size([139, 64])\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"import torch.nn as nn\n\n# Remove final fc layer to get embeddings\nresnet_features = nn.Sequential(*list(resnet50.children())[:-1]).to(device)\nresnet_features.eval()\n\ndef extract_mri_embeddings(dataloader):\n    embeddings, labels = [], []\n    with torch.no_grad():\n        for imgs, lbls in dataloader:\n            imgs = imgs.to(device)\n            emb = resnet_features(imgs)  # [batch, 2048,1,1]\n            emb = emb.view(emb.size(0), -1)  # flatten\n            embeddings.append(emb.cpu())\n            labels.append(lbls)\n    return torch.cat(embeddings, dim=0), torch.cat(labels, dim=0)\n\ntrain_mri_emb, train_mri_lbl = extract_mri_embeddings(train_loader)\nval_mri_emb, val_mri_lbl = extract_mri_embeddings(val_loader)\nprint(\"Train MRI embeddings:\", train_mri_emb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:19:07.822478Z","iopub.execute_input":"2026-01-31T14:19:07.823034Z","iopub.status.idle":"2026-01-31T14:27:41.224747Z","shell.execute_reply.started":"2026-01-31T14:19:07.823005Z","shell.execute_reply":"2026-01-31T14:27:41.224007Z"}},"outputs":[{"name":"stdout","text":"Train MRI embeddings: torch.Size([69149, 2048])\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"train_hw_emb = model_hw(X_scaled_train.to(device), return_embedding=True).cpu()\nval_hw_emb = model_hw(X_scaled_val.to(device), return_embedding=True).cpu()\nprint(\"Train Handwriting embeddings:\", train_hw_emb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:29:12.180421Z","iopub.execute_input":"2026-01-31T14:29:12.181013Z","iopub.status.idle":"2026-01-31T14:29:12.186555Z","shell.execute_reply.started":"2026-01-31T14:29:12.180984Z","shell.execute_reply":"2026-01-31T14:29:12.185930Z"}},"outputs":[{"name":"stdout","text":"Train Handwriting embeddings: torch.Size([139, 64])\n","output_type":"stream"}],"execution_count":107},{"cell_type":"markdown","source":"# Create Fusion Data Loaders","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\n# Concatenate MRI + handwriting embeddings\ntrain_fusion_input = torch.cat([train_mri_emb, train_hw_emb], dim=1)\nval_fusion_input = torch.cat([val_mri_emb, val_hw_emb], dim=1)\n\ntrain_dataset_fusion = TensorDataset(train_fusion_input, train_mri_lbl)  # labels same as MRI labels\nval_dataset_fusion = TensorDataset(val_fusion_input, val_mri_lbl)\n\ntrain_loader_fusion = DataLoader(train_dataset_fusion, batch_size=16, shuffle=True)\nval_loader_fusion = DataLoader(val_dataset_fusion, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:29:42.444118Z","iopub.execute_input":"2026-01-31T14:29:42.444474Z","iopub.status.idle":"2026-01-31T14:29:42.531007Z","shell.execute_reply.started":"2026-01-31T14:29:42.444433Z","shell.execute_reply":"2026-01-31T14:29:42.530185Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2024714698.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Concatenate MRI + handwriting embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_fusion_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mri_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hw_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_fusion_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_mri_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_hw_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 69149 but got size 139 for tensor number 1 in the list."],"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 1. Expected size 69149 but got size 139 for tensor number 1 in the list.","output_type":"error"}],"execution_count":108},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nMRI_PATH = \"/kaggle/input/imagesoasis/Data\"  # path to MRI images\n\n# Use ImageFolder\nmri_dataset = datasets.ImageFolder(MRI_PATH, transform=transform)\n\n# Split train/val\ntrain_size = int(0.8 * len(mri_dataset))\nval_size = len(mri_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(mri_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)  # shuffle=False to keep order\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:32:18.554084Z","iopub.execute_input":"2026-01-31T14:32:18.554360Z","iopub.status.idle":"2026-01-31T14:32:55.632261Z","shell.execute_reply.started":"2026-01-31T14:32:18.554335Z","shell.execute_reply":"2026-01-31T14:32:55.631524Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"import os\n\nslice_patient_ids = [os.path.basename(os.path.dirname(path)) for path, _ in mri_dataset.imgs]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:33:16.298666Z","iopub.execute_input":"2026-01-31T14:33:16.299372Z","iopub.status.idle":"2026-01-31T14:33:16.376741Z","shell.execute_reply.started":"2026-01-31T14:33:16.299341Z","shell.execute_reply":"2026-01-31T14:33:16.376082Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"from collections import defaultdict\nimport torch\n\n# Assume resnet_features is your trained ResNet50 feature extractor\nresnet_features.eval()\n\npatient_emb_dict = defaultdict(list)\npatient_label_dict = {}\n\nwith torch.no_grad():\n    for idx, (img, lbl) in enumerate(mri_dataset):\n        img = img.unsqueeze(0).to(device)  # add batch dim\n        emb = resnet_features(img).view(1, -1).cpu()  # flatten\n        patient_id = slice_patient_ids[idx]\n        patient_emb_dict[patient_id].append(emb)\n        patient_label_dict[patient_id] = lbl  # same for all slices\n\n# Average embeddings per patient\ntrain_mri_patient_emb = []\ntrain_mri_patient_lbl = []\n\nfor patient_id in patient_emb_dict:\n    emb = torch.cat(patient_emb_dict[patient_id], dim=0).mean(dim=0)\n    train_mri_patient_emb.append(emb)\n    train_mri_patient_lbl.append(patient_label_dict[patient_id])\n\ntrain_mri_patient_emb = torch.stack(train_mri_patient_emb)\ntrain_mri_patient_lbl = torch.tensor(train_mri_patient_lbl)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T14:33:28.901089Z","iopub.execute_input":"2026-01-31T14:33:28.901388Z","iopub.status.idle":"2026-01-31T14:46:58.757927Z","shell.execute_reply.started":"2026-01-31T14:33:28.901362Z","shell.execute_reply":"2026-01-31T14:46:58.757155Z"}},"outputs":[],"execution_count":112},{"cell_type":"markdown","source":"# Step 4: Fusion Network\n\nWe now concatenate MRI embeddings and handwriting embeddings for each patient.\nThe fused vector is input to a small MLP for final prediction.\n","metadata":{}},{"cell_type":"markdown","source":"## Fusion Network Definition","metadata":{}},{"cell_type":"code","source":"import torch\nfrom collections import defaultdict\nimport os\n\n# ResNet feature extractor (remove last fc layer)\nresnet_features = torch.nn.Sequential(*list(resnet50.children())[:-1]).to(device)\nresnet_features.eval()\n\n# Extract patient IDs from dataset paths (assuming ImageFolder structure)\nslice_patient_ids = [os.path.basename(os.path.dirname(path)) for path, _ in mri_dataset.imgs]\n\n# Store embeddings per patient\npatient_emb_dict = defaultdict(list)\npatient_label_dict = {}\n\nwith torch.no_grad():\n    for idx, (img, lbl) in enumerate(mri_dataset):\n        img = img.unsqueeze(0).to(device)\n        emb = resnet_features(img).view(1, -1).cpu()\n        patient_id = slice_patient_ids[idx]\n        patient_emb_dict[patient_id].append(emb)\n        patient_label_dict[patient_id] = lbl  # all slices same label\n\n# Average embeddings per patient\nmri_patient_emb = []\nmri_patient_lbl = []\n\nfor patient_id in patient_emb_dict:\n    emb = torch.cat(patient_emb_dict[patient_id], dim=0).mean(dim=0)\n    mri_patient_emb.append(emb)\n    mri_patient_lbl.append(patient_label_dict[patient_id])\n\nmri_patient_emb = torch.stack(mri_patient_emb)\nmri_patient_lbl = torch.tensor(mri_patient_lbl)\n\nprint(\"MRI patient-level embeddings:\", mri_patient_emb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:03:21.421507Z","iopub.execute_input":"2026-01-31T15:03:21.421805Z","iopub.status.idle":"2026-01-31T15:18:43.145539Z","shell.execute_reply.started":"2026-01-31T15:03:21.421776Z","shell.execute_reply":"2026-01-31T15:18:43.144792Z"}},"outputs":[{"name":"stdout","text":"MRI patient-level embeddings: torch.Size([4, 2048])\n","output_type":"stream"}],"execution_count":114},{"cell_type":"markdown","source":"# Prepare Handwriting embeddings","metadata":{}},{"cell_type":"code","source":"# Assuming you already trained Handwriting MLP and have X_scaled_train/X_scaled_val\n# Extract embeddings from trained handwriting model\nhw_embeddings = model_hw(X_scaled_train.to(device), return_embedding=True).cpu()\nhw_labels = torch.tensor(y_train)  # make sure labels match patients\n\nprint(\"Handwriting embeddings:\", hw_embeddings.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:20:48.863926Z","iopub.execute_input":"2026-01-31T15:20:48.864659Z","iopub.status.idle":"2026-01-31T15:20:48.870239Z","shell.execute_reply.started":"2026-01-31T15:20:48.864628Z","shell.execute_reply":"2026-01-31T15:20:48.869605Z"}},"outputs":[{"name":"stdout","text":"Handwriting embeddings: torch.Size([139, 64])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/4166320472.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  hw_labels = torch.tensor(y_train)  # make sure labels match patients\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# input dimension = MRI embedding dim + Handwriting embedding dim\nfusion_input_dim = train_fusion_input.shape[1]  # make sure you have train_fusion_input defined\nnum_classes = len(mri_dataset.classes)\n\nfusion_model = nn.Sequential(\n    nn.Linear(fusion_input_dim, 128),\n    nn.ReLU(),\n    nn.Linear(128, 64),\n    nn.ReLU(),\n    nn.Linear(64, num_classes)\n).to(device)\n\n# Load trained weights if saved\n# fusion_model.load_state_dict(torch.load(\"/kaggle/working/fusion_model.pth\"))\n\nfusion_model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:31:47.930992Z","iopub.execute_input":"2026-01-31T15:31:47.931489Z","iopub.status.idle":"2026-01-31T15:31:47.937606Z","shell.execute_reply.started":"2026-01-31T15:31:47.931462Z","shell.execute_reply":"2026-01-31T15:31:47.936771Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/158592670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input dimension = MRI embedding dim + Handwriting embedding dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfusion_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fusion_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# make sure you have train_fusion_input defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_fusion_input' is not defined"],"ename":"NameError","evalue":"name 'train_fusion_input' is not defined","output_type":"error"}],"execution_count":119},{"cell_type":"code","source":"import torch\n\n# Make sure embeddings are torch tensors\ntrain_mri_emb = train_mri_emb.float()  # e.g., [num_patients, 2048]\ntrain_hw_emb = train_hw_emb.float()    # e.g., [num_patients, 10]\n\n# Concatenate along feature dimension\ntrain_fusion_input = torch.cat([train_mri_emb, train_hw_emb], dim=1)\n\n# Labels\ntrain_fusion_labels = train_labels\n\nprint(\"Fusion input shape:\", train_fusion_input.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:34:19.150782Z","iopub.execute_input":"2026-01-31T15:34:19.151082Z","iopub.status.idle":"2026-01-31T15:34:19.157697Z","shell.execute_reply.started":"2026-01-31T15:34:19.151055Z","shell.execute_reply":"2026-01-31T15:34:19.156747Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3443141118.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Concatenate along feature dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_fusion_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mri_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hw_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 69149 but got size 139 for tensor number 1 in the list."],"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 1. Expected size 69149 but got size 139 for tensor number 1 in the list.","output_type":"error"}],"execution_count":121},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Make sure you have these variables defined from previous steps:\n# train_fusion_input.shape[1] = input dimension (MRI + Handwriting embeddings)\n# mri_dataset.classes = list of classes\n\nfusion_input_dim = train_fusion_input.shape[1]  # total embedding dimension\nnum_classes = len(mri_dataset.classes)\n\nfusion_model = nn.Sequential(\n    nn.Linear(fusion_input_dim, 128),\n    nn.ReLU(),\n    nn.Linear(128, 64),\n    nn.ReLU(),\n    nn.Linear(64, num_classes)\n).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:33:24.568685Z","iopub.execute_input":"2026-01-31T15:33:24.569168Z","iopub.status.idle":"2026-01-31T15:33:24.575531Z","shell.execute_reply.started":"2026-01-31T15:33:24.569144Z","shell.execute_reply":"2026-01-31T15:33:24.574661Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2428703700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# mri_dataset.classes = list of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfusion_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fusion_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# total embedding dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_fusion_input' is not defined"],"ename":"NameError","evalue":"name 'train_fusion_input' is not defined","output_type":"error"}],"execution_count":120},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}